{"cells":[{"cell_type":"code","source":["!pip install --upgrade pip -q\n!pip install progressbar -q\n!pip install memory_profiler -q\n!pip install --upgrade pandas>=1.2 -q"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cb667d2a-3b5f-410e-aaf4-dd439732c51e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%load_ext memory_profiler"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"28d273c8-e128-4b73-9b5e-aa4eab0656df"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">The memory_profiler extension is already loaded. To reload it, use:\n  %reload_ext memory_profiler\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The memory_profiler extension is already loaded. To reload it, use:\n  %reload_ext memory_profiler\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import urllib\nimport tarfile\nimport os\nfrom collections import OrderedDict\nimport warnings\nimport random\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport progressbar\nfrom scipy.sparse import csr_matrix\n\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.feature_extraction import FeatureHasher\nfrom sklearn import linear_model\nfrom sklearn.metrics import roc_auc_score, log_loss"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b638cb6c-d45d-4a28-8839-bb1c5dad06f1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Download Criteo  Display Advertising Challenge dataset"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c53bbab7-6051-4983-96e3-793ee117588b"}}},{"cell_type":"code","source":["# ProgressBar borrowed from https://stackoverflow.com/a/53643011/2015762\nclass ProgressBar():\n    def __init__(self):\n        self.pbar = None\n\n    def __call__(self, block_num, block_size, total_size):\n        if not self.pbar:\n            self.pbar=progressbar.ProgressBar(maxval=total_size)\n            self.pbar.start()\n\n        downloaded = block_num * block_size\n        if downloaded < total_size:\n            self.pbar.update(downloaded)\n        else:\n            self.pbar.finish()\n\n\ndef download_dataset(dataset_url, dataset_folder_path, compressed_dataset_path):\n    # Download dataset\n    os.makedirs(dataset_folder_path, exist_ok=True)\n    urllib.request.urlretrieve(dataset_url, compressed_dataset_path, ProgressBar())\n\ndef extract_dataset(compressed_dataset_path, dataset_folder_path, dataset_path):\n    # Extract train.txt (dataset with labels) and readme\n    with tarfile.open(compressed_dataset_path, \"r\") as input_file:\n        input_file.extract('readme.txt', dataset_folder_path)\n        input_file.extract('train.txt', dataset_folder_path)\n        os.rename(os.path.join(dataset_folder_path, 'train.txt'), dataset_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"af3c5721-fde1-4c56-8437-57d8e8bc5311"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["dataset_url = \"https://criteostorage.blob.core.windows.net/criteo-research-datasets/kaggle-display-advertising-challenge-dataset.tar.gz\"\ndataset_folder_path = os.path.abspath('sync/data/criteo_dataset')\ncompressed_dataset_path = os.path.join(dataset_folder_path, \"criteo_dataset.tar.gz\")\ndataset_path = os.path.join(dataset_folder_path, \"criteo_dataset.txt\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1478b2f8-d38d-47c0-83da-60b9bc391b2b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["if not os.path.exists(compressed_dataset_path):\n    download_dataset(dataset_url, dataset_folder_path, compressed_dataset_path)\n\nif not os.path.exists(dataset_path):\n    extract_dataset(compressed_dataset_path, dataset_folder_path, dataset_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"63ada22d-76b5-4e2c-932a-69c89e541765"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["If it takes too much time, download this smaller dataset instead"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8f0defb5-3d8c-4955-980e-4e408af3b46b"}}},{"cell_type":"code","source":["# toy_dataset_path = os.path.join(dataset_folder_path, \"criteo_toy_dataset.txt\")\n# toy_dataset_url = 'https://www.dropbox.com/s/dle2t3szhljfevh/criteo_toy_dataset.txt?dl=1'\n# urllib.request.urlretrieve(toy_dataset_url, toy_dataset_path, ProgressBar())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"231628d5-9e06-4ae7-8f44-25ca7ee6c9c0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Quick look at the files we have downloaded.\n\nWithin iPython notebook, we can execute bash command by prepending the cell with `!` and insert python variable into it with `{}`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"55660968-0843-4d77-a996-c0970110f7bc"}}},{"cell_type":"code","source":["!ls -alh {dataset_folder_path}"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"99c7acfc-a685-4e49-a609-a409d6199f62"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">total 16G\r\ndrwxr-xr-x 2 root      root  4.0K Mar 12 15:20 .\r\ndrwxr-xr-x 3 root      root  4.0K Mar 12 12:46 ..\r\n-rw-r--r-- 1 root      root  4.3G Mar 12 15:15 criteo_dataset.tar.gz\r\n-rw-r--r-- 1 293604138 staff  11G May 12  2014 criteo_dataset.txt\r\n-rw-r--r-- 1 root      root   23M Mar 12 15:55 criteo_test_dataset.txt\r\n-rw-r--r-- 1 root      root  231M Mar 12 17:14 criteo_toy_dataset.txt\r\n-rw-r--r-- 1 root      root  208M Mar 12 15:55 criteo_train_dataset.txt\r\n-rw-r--r-- 1 293604138 staff 1.9K Aug 22  2014 readme.txt\r\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">total 16G\r\ndrwxr-xr-x 2 root      root  4.0K Mar 12 15:20 .\r\ndrwxr-xr-x 3 root      root  4.0K Mar 12 12:46 ..\r\n-rw-r--r-- 1 root      root  4.3G Mar 12 15:15 criteo_dataset.tar.gz\r\n-rw-r--r-- 1 293604138 staff  11G May 12  2014 criteo_dataset.txt\r\n-rw-r--r-- 1 root      root   23M Mar 12 15:55 criteo_test_dataset.txt\r\n-rw-r--r-- 1 root      root  231M Mar 12 17:14 criteo_toy_dataset.txt\r\n-rw-r--r-- 1 root      root  208M Mar 12 15:55 criteo_train_dataset.txt\r\n-rw-r--r-- 1 293604138 staff 1.9K Aug 22  2014 readme.txt\r\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["!cat {dataset_folder_path}/readme.txt"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"99f480f9-5224-419b-904a-fc38429d97e6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">        ------ Display Advertising Challenge ------\r\n\r\nDataset: dac-v1\r\n\r\nThis dataset contains feature values and click feedback for millions of display \r\nads. Its purpose is to benchmark algorithms for clickthrough rate (CTR) prediction.\r\nIt has been used for the Display Advertising Challenge hosted by Kaggle:\r\nhttps://www.kaggle.com/c/criteo-display-ad-challenge/\r\n\r\n===================================================\r\n\r\nFull description:\r\n\r\nThis dataset contains 2 files:\r\n  train.txt\r\n  test.txt\r\ncorresponding to the training and test parts of the data. \r\n\r\n====================================================\r\n\r\nDataset construction:\r\n\r\nThe training dataset consists of a portion of Criteo&#39;s traffic over a period\r\nof 7 days. Each row corresponds to a display ad served by Criteo and the first\r\ncolumn is indicates whether this ad has been clicked or not.\r\nThe positive (clicked) and negatives (non-clicked) examples have both been\r\nsubsampled (but at different rates) in order to reduce the dataset size.\r\n\r\nThere are 13 features taking integer values (mostly count features) and 26\r\ncategorical features. The values of the categorical features have been hashed\r\nonto 32 bits for anonymization purposes. \r\nThe semantic of these features is undisclosed. Some features may have missing values.\r\n\r\nThe rows are chronologically ordered.\r\n\r\nThe test set is computed in the same way as the training set but it \r\ncorresponds to events on the day following the training period. \r\nThe first column (label) has been removed.\r\n\r\n====================================================\r\n\r\nFormat:\r\n\r\nThe columns are tab separeted with the following schema:\r\n&lt;label&gt; &lt;integer feature 1&gt; ... &lt;integer feature 13&gt; &lt;categorical feature 1&gt; ... &lt;categorical feature 26&gt;\r\n\r\nWhen a value is missing, the field is just empty.\r\nThere is no label field in the test set.\r\n\r\n====================================================\r\n\r\nDataset assembled by Olivier Chapelle (o.chapelle@criteo.com)\r\n\r\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">        ------ Display Advertising Challenge ------\r\n\r\nDataset: dac-v1\r\n\r\nThis dataset contains feature values and click feedback for millions of display \r\nads. Its purpose is to benchmark algorithms for clickthrough rate (CTR) prediction.\r\nIt has been used for the Display Advertising Challenge hosted by Kaggle:\r\nhttps://www.kaggle.com/c/criteo-display-ad-challenge/\r\n\r\n===================================================\r\n\r\nFull description:\r\n\r\nThis dataset contains 2 files:\r\n  train.txt\r\n  test.txt\r\ncorresponding to the training and test parts of the data. \r\n\r\n====================================================\r\n\r\nDataset construction:\r\n\r\nThe training dataset consists of a portion of Criteo&#39;s traffic over a period\r\nof 7 days. Each row corresponds to a display ad served by Criteo and the first\r\ncolumn is indicates whether this ad has been clicked or not.\r\nThe positive (clicked) and negatives (non-clicked) examples have both been\r\nsubsampled (but at different rates) in order to reduce the dataset size.\r\n\r\nThere are 13 features taking integer values (mostly count features) and 26\r\ncategorical features. The values of the categorical features have been hashed\r\nonto 32 bits for anonymization purposes. \r\nThe semantic of these features is undisclosed. Some features may have missing values.\r\n\r\nThe rows are chronologically ordered.\r\n\r\nThe test set is computed in the same way as the training set but it \r\ncorresponds to events on the day following the training period. \r\nThe first column (label) has been removed.\r\n\r\n====================================================\r\n\r\nFormat:\r\n\r\nThe columns are tab separeted with the following schema:\r\n&lt;label&gt; &lt;integer feature 1&gt; ... &lt;integer feature 13&gt; &lt;categorical feature 1&gt; ... &lt;categorical feature 26&gt;\r\n\r\nWhen a value is missing, the field is just empty.\r\nThere is no label field in the test set.\r\n\r\n====================================================\r\n\r\nDataset assembled by Olivier Chapelle (o.chapelle@criteo.com)\r\n\r\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["label_columns = ['label']\ninteger_features = [f'int_feat_{i}' for i in range(1, 14)]\ncategorical_features = [f'cat_feat_{i}' for i in range(1, 27)]\ncolumns = label_columns + integer_features + categorical_features"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"83209dbe-6666-43d0-8ab2-c9a7139ae4e3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["pd.read_csv(dataset_path, nrows=10, header=None, sep='\\t', names=columns)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"97987163-55dc-4807-a4e8-0d5db8781629"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[84]: </div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[84]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>int_feat_1</th>\n      <th>int_feat_2</th>\n      <th>int_feat_3</th>\n      <th>int_feat_4</th>\n      <th>int_feat_5</th>\n      <th>int_feat_6</th>\n      <th>int_feat_7</th>\n      <th>int_feat_8</th>\n      <th>int_feat_9</th>\n      <th>int_feat_10</th>\n      <th>int_feat_11</th>\n      <th>int_feat_12</th>\n      <th>int_feat_13</th>\n      <th>cat_feat_1</th>\n      <th>cat_feat_2</th>\n      <th>cat_feat_3</th>\n      <th>cat_feat_4</th>\n      <th>cat_feat_5</th>\n      <th>cat_feat_6</th>\n      <th>cat_feat_7</th>\n      <th>cat_feat_8</th>\n      <th>cat_feat_9</th>\n      <th>cat_feat_10</th>\n      <th>cat_feat_11</th>\n      <th>cat_feat_12</th>\n      <th>cat_feat_13</th>\n      <th>cat_feat_14</th>\n      <th>cat_feat_15</th>\n      <th>cat_feat_16</th>\n      <th>cat_feat_17</th>\n      <th>cat_feat_18</th>\n      <th>cat_feat_19</th>\n      <th>cat_feat_20</th>\n      <th>cat_feat_21</th>\n      <th>cat_feat_22</th>\n      <th>cat_feat_23</th>\n      <th>cat_feat_24</th>\n      <th>cat_feat_25</th>\n      <th>cat_feat_26</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>1382</td>\n      <td>4.0</td>\n      <td>15</td>\n      <td>2</td>\n      <td>181</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>68fd1e64</td>\n      <td>80e26c9b</td>\n      <td>fb936136</td>\n      <td>7b4723c4</td>\n      <td>25c83c98</td>\n      <td>7e0ccccf</td>\n      <td>de7995b8</td>\n      <td>1f89b562</td>\n      <td>a73ee510</td>\n      <td>a8cd5504</td>\n      <td>b2cb9c98</td>\n      <td>37c9c164</td>\n      <td>2824a5f6</td>\n      <td>1adce6ef</td>\n      <td>8ba8b39a</td>\n      <td>891b62e7</td>\n      <td>e5ba7672</td>\n      <td>f54016b9</td>\n      <td>21ddcdc9</td>\n      <td>b1252a9d</td>\n      <td>07b5194c</td>\n      <td>NaN</td>\n      <td>3a171ecb</td>\n      <td>c5c50484</td>\n      <td>e8b83407</td>\n      <td>9727dd16</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>44.0</td>\n      <td>1.0</td>\n      <td>102</td>\n      <td>8.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>68fd1e64</td>\n      <td>f0cf0024</td>\n      <td>6f67f7e5</td>\n      <td>41274cd7</td>\n      <td>25c83c98</td>\n      <td>fe6b92e5</td>\n      <td>922afcc0</td>\n      <td>0b153874</td>\n      <td>a73ee510</td>\n      <td>2b53e5fb</td>\n      <td>4f1b46f3</td>\n      <td>623049e6</td>\n      <td>d7020589</td>\n      <td>b28479f6</td>\n      <td>e6c5b5cd</td>\n      <td>c92f3b61</td>\n      <td>07c540c4</td>\n      <td>b04e4670</td>\n      <td>21ddcdc9</td>\n      <td>5840adea</td>\n      <td>60f6221e</td>\n      <td>NaN</td>\n      <td>3a171ecb</td>\n      <td>43f13e8b</td>\n      <td>e8b83407</td>\n      <td>731c3655</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>14.0</td>\n      <td>767</td>\n      <td>89.0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>245</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>45.0</td>\n      <td>287e684f</td>\n      <td>0a519c5c</td>\n      <td>02cf9876</td>\n      <td>c18be181</td>\n      <td>25c83c98</td>\n      <td>7e0ccccf</td>\n      <td>c78204a1</td>\n      <td>0b153874</td>\n      <td>a73ee510</td>\n      <td>3b08e48b</td>\n      <td>5f5e6091</td>\n      <td>8fe001f4</td>\n      <td>aa655a2f</td>\n      <td>07d13a8f</td>\n      <td>6dc710ed</td>\n      <td>36103458</td>\n      <td>8efede7f</td>\n      <td>3412118d</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>e587c466</td>\n      <td>ad3062eb</td>\n      <td>3a171ecb</td>\n      <td>3b183c5c</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>893</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4392</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>68fd1e64</td>\n      <td>2c16a946</td>\n      <td>a9a87e68</td>\n      <td>2e17d6f6</td>\n      <td>25c83c98</td>\n      <td>fe6b92e5</td>\n      <td>2e8a689b</td>\n      <td>0b153874</td>\n      <td>a73ee510</td>\n      <td>efea433b</td>\n      <td>e51ddf94</td>\n      <td>a30567ca</td>\n      <td>3516f6e6</td>\n      <td>07d13a8f</td>\n      <td>18231224</td>\n      <td>52b8680f</td>\n      <td>1e88c74f</td>\n      <td>74ef3502</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6b3a5ca6</td>\n      <td>NaN</td>\n      <td>3a171ecb</td>\n      <td>9117a34a</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3.0</td>\n      <td>-1</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>8cf07265</td>\n      <td>ae46a29d</td>\n      <td>c81688bb</td>\n      <td>f922efad</td>\n      <td>25c83c98</td>\n      <td>13718bbd</td>\n      <td>ad9fa255</td>\n      <td>0b153874</td>\n      <td>a73ee510</td>\n      <td>5282c137</td>\n      <td>e5d8af57</td>\n      <td>66a76a26</td>\n      <td>f06c53ac</td>\n      <td>1adce6ef</td>\n      <td>8ff4b403</td>\n      <td>01adbab4</td>\n      <td>1e88c74f</td>\n      <td>26b3c7a7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21c9516a</td>\n      <td>NaN</td>\n      <td>32c7478e</td>\n      <td>b34f3128</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>-1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12824</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>05db9164</td>\n      <td>6c9c9cf3</td>\n      <td>2730ec9c</td>\n      <td>5400db8b</td>\n      <td>43b19349</td>\n      <td>6f6d9be8</td>\n      <td>53b5f978</td>\n      <td>0b153874</td>\n      <td>a73ee510</td>\n      <td>3b08e48b</td>\n      <td>91e8fc27</td>\n      <td>be45b877</td>\n      <td>9ff13f22</td>\n      <td>07d13a8f</td>\n      <td>06969a20</td>\n      <td>9bc7fff5</td>\n      <td>776ce399</td>\n      <td>92555263</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>242bb710</td>\n      <td>8ec974f4</td>\n      <td>be7c41b4</td>\n      <td>72c78f11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>3168</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>439a44a4</td>\n      <td>ad4527a2</td>\n      <td>c02372d0</td>\n      <td>d34ebbaa</td>\n      <td>43b19349</td>\n      <td>fe6b92e5</td>\n      <td>4bc6ffea</td>\n      <td>0b153874</td>\n      <td>a73ee510</td>\n      <td>3b08e48b</td>\n      <td>a4609aab</td>\n      <td>14d63538</td>\n      <td>772a00d7</td>\n      <td>07d13a8f</td>\n      <td>f9d1382e</td>\n      <td>b00d3dc9</td>\n      <td>776ce399</td>\n      <td>cdfa8259</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20062612</td>\n      <td>NaN</td>\n      <td>93bad2c0</td>\n      <td>1b256e61</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>68fd1e64</td>\n      <td>2c16a946</td>\n      <td>503b9dbc</td>\n      <td>e4dbea90</td>\n      <td>f3474129</td>\n      <td>13718bbd</td>\n      <td>38eb9cf4</td>\n      <td>1f89b562</td>\n      <td>a73ee510</td>\n      <td>547c0ffe</td>\n      <td>bc8c9f21</td>\n      <td>60ab2f07</td>\n      <td>46f42a63</td>\n      <td>07d13a8f</td>\n      <td>18231224</td>\n      <td>e6b6bdc7</td>\n      <td>e5ba7672</td>\n      <td>74ef3502</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5316a17f</td>\n      <td>NaN</td>\n      <td>32c7478e</td>\n      <td>9117a34a</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>44</td>\n      <td>4.0</td>\n      <td>8.0</td>\n      <td>19010</td>\n      <td>249.0</td>\n      <td>28</td>\n      <td>31</td>\n      <td>141</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>8.0</td>\n      <td>05db9164</td>\n      <td>d833535f</td>\n      <td>d032c263</td>\n      <td>c18be181</td>\n      <td>25c83c98</td>\n      <td>7e0ccccf</td>\n      <td>d5b6acf2</td>\n      <td>0b153874</td>\n      <td>a73ee510</td>\n      <td>2acdcf4e</td>\n      <td>086ac2d2</td>\n      <td>dfbb09fb</td>\n      <td>41a6ae00</td>\n      <td>b28479f6</td>\n      <td>e2502ec9</td>\n      <td>84898b2a</td>\n      <td>e5ba7672</td>\n      <td>42a2edb9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0014c32a</td>\n      <td>NaN</td>\n      <td>32c7478e</td>\n      <td>3b183c5c</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>35</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>33737</td>\n      <td>21.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>05db9164</td>\n      <td>510b40a5</td>\n      <td>d03e7c24</td>\n      <td>eb1fd928</td>\n      <td>25c83c98</td>\n      <td>NaN</td>\n      <td>52283d1c</td>\n      <td>0b153874</td>\n      <td>a73ee510</td>\n      <td>015ac893</td>\n      <td>e51ddf94</td>\n      <td>951fe4a9</td>\n      <td>3516f6e6</td>\n      <td>07d13a8f</td>\n      <td>2ae4121c</td>\n      <td>8ec71479</td>\n      <td>d4bb7bd8</td>\n      <td>70d0f5f9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0e63fca0</td>\n      <td>NaN</td>\n      <td>32c7478e</td>\n      <td>0e8fe315</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>int_feat_1</th>\n      <th>int_feat_2</th>\n      <th>int_feat_3</th>\n      <th>int_feat_4</th>\n      <th>int_feat_5</th>\n      <th>int_feat_6</th>\n      <th>int_feat_7</th>\n      <th>int_feat_8</th>\n      <th>int_feat_9</th>\n      <th>int_feat_10</th>\n      <th>int_feat_11</th>\n      <th>int_feat_12</th>\n      <th>int_feat_13</th>\n      <th>cat_feat_1</th>\n      <th>cat_feat_2</th>\n      <th>cat_feat_3</th>\n      <th>cat_feat_4</th>\n      <th>cat_feat_5</th>\n      <th>cat_feat_6</th>\n      <th>cat_feat_7</th>\n      <th>cat_feat_8</th>\n      <th>cat_feat_9</th>\n      <th>cat_feat_10</th>\n      <th>cat_feat_11</th>\n      <th>cat_feat_12</th>\n      <th>cat_feat_13</th>\n      <th>cat_feat_14</th>\n      <th>cat_feat_15</th>\n      <th>cat_feat_16</th>\n      <th>cat_feat_17</th>\n      <th>cat_feat_18</th>\n      <th>cat_feat_19</th>\n      <th>cat_feat_20</th>\n      <th>cat_feat_21</th>\n      <th>cat_feat_22</th>\n      <th>cat_feat_23</th>\n      <th>cat_feat_24</th>\n      <th>cat_feat_25</th>\n      <th>cat_feat_26</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>1382</td>\n      <td>4.0</td>\n      <td>15</td>\n      <td>2</td>\n      <td>181</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>68fd1e64</td>\n      <td>80e26c9b</td>\n      <td>fb936136</td>\n      <td>7b4723c4</td>\n      <td>25c83c98</td>\n      <td>7e0ccccf</td>\n      <td>de7995b8</td>\n      <td>1f89b562</td>\n      <td>a73ee510</td>\n      <td>a8cd5504</td>\n      <td>b2cb9c98</td>\n      <td>37c9c164</td>\n      <td>2824a5f6</td>\n      <td>1adce6ef</td>\n      <td>8ba8b39a</td>\n      <td>891b62e7</td>\n      <td>e5ba7672</td>\n      <td>f54016b9</td>\n      <td>21ddcdc9</td>\n      <td>b1252a9d</td>\n      <td>07b5194c</td>\n      <td>NaN</td>\n      <td>3a171ecb</td>\n      <td>c5c50484</td>\n      <td>e8b83407</td>\n      <td>9727dd16</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>44.0</td>\n      <td>1.0</td>\n      <td>102</td>\n      <td>8.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>68fd1e64</td>\n      <td>f0cf0024</td>\n      <td>6f67f7e5</td>\n      <td>41274cd7</td>\n      <td>25c83c98</td>\n      <td>fe6b92e5</td>\n      <td>922afcc0</td>\n      <td>0b153874</td>\n      <td>a73ee510</td>\n      <td>2b53e5fb</td>\n      <td>4f1b46f3</td>\n      <td>623049e6</td>\n      <td>d7020589</td>\n      <td>b28479f6</td>\n      <td>e6c5b5cd</td>\n      <td>c92f3b61</td>\n      <td>07c540c4</td>\n      <td>b04e4670</td>\n      <td>21ddcdc9</td>\n      <td>5840adea</td>\n      <td>60f6221e</td>\n      <td>NaN</td>\n      <td>3a171ecb</td>\n      <td>43f13e8b</td>\n      <td>e8b83407</td>\n      <td>731c3655</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>14.0</td>\n      <td>767</td>\n      <td>89.0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>245</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>45.0</td>\n      <td>287e684f</td>\n      <td>0a519c5c</td>\n      <td>02cf9876</td>\n      <td>c18be181</td>\n      <td>25c83c98</td>\n      <td>7e0ccccf</td>\n      <td>c78204a1</td>\n      <td>0b153874</td>\n      <td>a73ee510</td>\n      <td>3b08e48b</td>\n      <td>5f5e6091</td>\n      <td>8fe001f4</td>\n      <td>aa655a2f</td>\n      <td>07d13a8f</td>\n      <td>6dc710ed</td>\n      <td>36103458</td>\n      <td>8efede7f</td>\n      <td>3412118d</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>e587c466</td>\n      <td>ad3062eb</td>\n      <td>3a171ecb</td>\n      <td>3b183c5c</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>893</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4392</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>68fd1e64</td>\n      <td>2c16a946</td>\n      <td>a9a87e68</td>\n      <td>2e17d6f6</td>\n      <td>25c83c98</td>\n      <td>fe6b92e5</td>\n      <td>2e8a689b</td>\n      <td>0b153874</td>\n      <td>a73ee510</td>\n      <td>efea433b</td>\n      <td>e51ddf94</td>\n      <td>a30567ca</td>\n      <td>3516f6e6</td>\n      <td>07d13a8f</td>\n      <td>18231224</td>\n      <td>52b8680f</td>\n      <td>1e88c74f</td>\n      <td>74ef3502</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6b3a5ca6</td>\n      <td>NaN</td>\n      <td>3a171ecb</td>\n      <td>9117a34a</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3.0</td>\n      <td>-1</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>8cf07265</td>\n      <td>ae46a29d</td>\n      <td>c81688bb</td>\n      <td>f922efad</td>\n      <td>25c83c98</td>\n      <td>13718bbd</td>\n      <td>ad9fa255</td>\n      <td>0b153874</td>\n      <td>a73ee510</td>\n      <td>5282c137</td>\n      <td>e5d8af57</td>\n      <td>66a76a26</td>\n      <td>f06c53ac</td>\n      <td>1adce6ef</td>\n      <td>8ff4b403</td>\n      <td>01adbab4</td>\n      <td>1e88c74f</td>\n      <td>26b3c7a7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21c9516a</td>\n      <td>NaN</td>\n      <td>32c7478e</td>\n      <td>b34f3128</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>-1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12824</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>05db9164</td>\n      <td>6c9c9cf3</td>\n      <td>2730ec9c</td>\n      <td>5400db8b</td>\n      <td>43b19349</td>\n      <td>6f6d9be8</td>\n      <td>53b5f978</td>\n      <td>0b153874</td>\n      <td>a73ee510</td>\n      <td>3b08e48b</td>\n      <td>91e8fc27</td>\n      <td>be45b877</td>\n      <td>9ff13f22</td>\n      <td>07d13a8f</td>\n      <td>06969a20</td>\n      <td>9bc7fff5</td>\n      <td>776ce399</td>\n      <td>92555263</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>242bb710</td>\n      <td>8ec974f4</td>\n      <td>be7c41b4</td>\n      <td>72c78f11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>3168</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>439a44a4</td>\n      <td>ad4527a2</td>\n      <td>c02372d0</td>\n      <td>d34ebbaa</td>\n      <td>43b19349</td>\n      <td>fe6b92e5</td>\n      <td>4bc6ffea</td>\n      <td>0b153874</td>\n      <td>a73ee510</td>\n      <td>3b08e48b</td>\n      <td>a4609aab</td>\n      <td>14d63538</td>\n      <td>772a00d7</td>\n      <td>07d13a8f</td>\n      <td>f9d1382e</td>\n      <td>b00d3dc9</td>\n      <td>776ce399</td>\n      <td>cdfa8259</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20062612</td>\n      <td>NaN</td>\n      <td>93bad2c0</td>\n      <td>1b256e61</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>68fd1e64</td>\n      <td>2c16a946</td>\n      <td>503b9dbc</td>\n      <td>e4dbea90</td>\n      <td>f3474129</td>\n      <td>13718bbd</td>\n      <td>38eb9cf4</td>\n      <td>1f89b562</td>\n      <td>a73ee510</td>\n      <td>547c0ffe</td>\n      <td>bc8c9f21</td>\n      <td>60ab2f07</td>\n      <td>46f42a63</td>\n      <td>07d13a8f</td>\n      <td>18231224</td>\n      <td>e6b6bdc7</td>\n      <td>e5ba7672</td>\n      <td>74ef3502</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5316a17f</td>\n      <td>NaN</td>\n      <td>32c7478e</td>\n      <td>9117a34a</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>44</td>\n      <td>4.0</td>\n      <td>8.0</td>\n      <td>19010</td>\n      <td>249.0</td>\n      <td>28</td>\n      <td>31</td>\n      <td>141</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>8.0</td>\n      <td>05db9164</td>\n      <td>d833535f</td>\n      <td>d032c263</td>\n      <td>c18be181</td>\n      <td>25c83c98</td>\n      <td>7e0ccccf</td>\n      <td>d5b6acf2</td>\n      <td>0b153874</td>\n      <td>a73ee510</td>\n      <td>2acdcf4e</td>\n      <td>086ac2d2</td>\n      <td>dfbb09fb</td>\n      <td>41a6ae00</td>\n      <td>b28479f6</td>\n      <td>e2502ec9</td>\n      <td>84898b2a</td>\n      <td>e5ba7672</td>\n      <td>42a2edb9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0014c32a</td>\n      <td>NaN</td>\n      <td>32c7478e</td>\n      <td>3b183c5c</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>35</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>33737</td>\n      <td>21.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>05db9164</td>\n      <td>510b40a5</td>\n      <td>d03e7c24</td>\n      <td>eb1fd928</td>\n      <td>25c83c98</td>\n      <td>NaN</td>\n      <td>52283d1c</td>\n      <td>0b153874</td>\n      <td>a73ee510</td>\n      <td>015ac893</td>\n      <td>e51ddf94</td>\n      <td>951fe4a9</td>\n      <td>3516f6e6</td>\n      <td>07d13a8f</td>\n      <td>2ae4121c</td>\n      <td>8ec71479</td>\n      <td>d4bb7bd8</td>\n      <td>70d0f5f9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0e63fca0</td>\n      <td>NaN</td>\n      <td>32c7478e</td>\n      <td>0e8fe315</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Reading data with memory constraints"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"48033b2b-08be-4490-b9c8-4d6c8d61b38d"}}},{"cell_type":"markdown","source":["We first create a toy dataset with \"only\" 1 million rows (out of 45 millions)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"23587706-411e-487a-89b6-2423b7e389dc"}}},{"cell_type":"code","source":["toy_dataset_path = os.path.join(dataset_folder_path, \"criteo_toy_dataset.txt\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c1015efa-7924-4f3a-8bac-0c0fc691d425"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["!head -n 1000000 {dataset_path} > {toy_dataset_path}"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"13ad4dd2-c2d8-4c3f-bde2-c5cdd82933d7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Let's say we want to perform a basic operation: estimate the number of positive samples within the data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"543acccb-6454-4ffe-960d-0dcbc33894b7"}}},{"cell_type":"markdown","source":["### Basic approach"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e85b4203-6efc-46f0-ba5b-52ebe297b95a"}}},{"cell_type":"code","source":["def compute_positive_label_proportion(dataset_path, columns):\n    df = pd.read_csv(dataset_path, sep=\"\\t\", header=None, names=columns, usecols=['label'])\n    return df['label'].mean()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3d57d10b-15ee-4e3d-82fc-495d40a6b376"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Let's measure its memory footprint with the `%%memit` magic function"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fceb5b2b-9553-44a7-8d83-030409be41d9"}}},{"cell_type":"code","source":["%%memit\npositive_label_proportion = compute_positive_label_proportion(toy_dataset_path, columns)\nprint('positive_label_proportion', positive_label_proportion)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dafb5614-7640-4d36-a0f1-eac939d24f65"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">positive_label_proportion 0.254949\npeak memory: 403.34 MiB, increment: 0.02 MiB\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">positive_label_proportion 0.254949\npeak memory: 403.34 MiB, increment: 0.02 MiB\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["What would happen if you run the same function on a 45 times bigger dataset ?\n\nYou can give a try with `compute_positive_label_proportion(dataset_path, columns)`... at your own risks."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"83936c1c-2f35-47df-9daf-0ea7b4036e92"}}},{"cell_type":"markdown","source":["### Specifying column types\nWe can help pandas by specifying the column types to be used such that it does not need to infer it. Do so with the parameter dtype of pd.read_csv: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7ba93320-7ce7-4a5c-b36f-f1e9f86a1528"}}},{"cell_type":"code","source":["col_types = OrderedDict()\nfor col_name in columns:\n    if col_name in label_columns: col_type = 'bool'\n    if col_name in integer_features: col_type = 'float32'\n    if col_name in categorical_features: col_type = 'str'\n    col_types[col_name] = col_type\n\ndef compute_positive_label_proportion_with_dtype(dataset_path, columns, col_types):\n    # Read csv with dtype and return positive_label_proportion\n    df = pd.read_csv(dataset_path, sep=\"\\t\", header=None, names=columns, dtype=col_types)\n    return df['label'].mean()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"66f49dc1-bf77-4b33-b4f9-85a8c4f2cbe6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%%memit\npositive_label_proportion = compute_positive_label_proportion_with_dtype(toy_dataset_path, columns, col_types)\nprint('positive_label_proportion', positive_label_proportion)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7e275dee-57b0-4e2e-9d14-775b3c07daba"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">positive_label_proportion 0.254949\npeak memory: 1108.75 MiB, increment: 705.42 MiB\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">positive_label_proportion 0.254949\npeak memory: 1108.75 MiB, increment: 705.42 MiB\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Reading data by chunks\nWe can control the amount of memory we need by loading only a small chunk of the data and processing it before moving to the next chunk.\n\nSee documentation at https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#iterating-through-files-chunk-by-chunk\n\n```\nreader = pd.read_csv(..., chunksize=10, nrows=100):\nfor chunk in reader:\n    print(chunk)\n```"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"56287730-4405-4ae2-90a2-cedf29035f80"}}},{"cell_type":"code","source":["def compute_positive_label_proportion_with_dtype_and_chunksize(dataset_path, columns, col_types, chunksize):\n    # Read csv with dtype and chunksize and return positive_label_proportion\n    reader = pd.read_csv(\n        dataset_path, sep=\"\\t\", header=None, names=columns, dtype=col_types, chunksize=chunksize, \n    )\n    sum_labels = 0\n    sum_rows = 0\n    for chunk in reader:\n        sum_labels += chunk['label'].sum()\n        sum_rows += len(chunk)\n    return sum_labels / sum_rows"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d3c192e9-b4aa-4b81-9abc-9258896a506d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%%memit\npositive_label_proportion = compute_positive_label_proportion_with_dtype_and_chunksize(toy_dataset_path, columns, col_types, 100_000)\nprint('positive_label_proportion', positive_label_proportion)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"68a665f7-489e-4484-8cf3-4d376d1ea657"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">positive_label_proportion 0.254949\npeak memory: 471.07 MiB, increment: 43.71 MiB\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">positive_label_proportion 0.254949\npeak memory: 471.07 MiB, increment: 43.71 MiB\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["This can now be applied to the full dataset with no memory issue."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a5625703-6f57-414d-a2f6-25d86f4ae4fb"}}},{"cell_type":"code","source":["%%memit\npositive_label_proportion = compute_positive_label_proportion_with_dtype_and_chunksize(dataset_path, columns, col_types, 100_000)\nprint('positive_label_proportion', positive_label_proportion)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9f925158-ac73-4723-be68-249d05c75f5c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Training and evaluation"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4722389c-73ce-482b-b494-a363950f2276"}}},{"cell_type":"markdown","source":["### Split train and test datasets\nSince the datasets contain one line per example, we can split them into train and test by simply iterating over the lines. For each line in the original dataset: write it to the test data set with a probability p and write it to the train dataset with a probability 1 - p."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f7b3b941-be9a-4dff-ac77-fb980120f091"}}},{"cell_type":"code","source":["def split_train_test(full_dataset_path, train_dataset_path, test_dataset_path, test_ratio, seed=302984, print_every=None):\n    random.seed(seed)\n    with open(full_dataset_path, 'r') as input_file, open(train_dataset_path, 'w') as train_file, open(test_dataset_path, 'w') as test_file:\n        for i, line in enumerate(input_file):\n            if random.uniform(0, 1) <= test_ratio:\n                test_file.write(line)\n            else:\n                train_file.write(line)\n            \n            if print_every is not None and (i + 1) % print_every == 0:\n                print(f\"Processed {i + 1} lines\")\n        print(f\"Processed {i + 1} lines\")\n        \ntrain_dataset_path = os.path.join(dataset_folder_path, \"criteo_train_dataset.txt\")\ntest_dataset_path = os.path.join(dataset_folder_path, \"criteo_test_dataset.txt\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6ddfeb48-4ac1-43ef-9c14-ff395c0fcb18"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["if not os.path.exists(train_dataset_path) or not os.path.exists(test_dataset_path):\n    split_train_test(dataset_path, train_dataset_path, test_dataset_path, test_ratio=0.1, print_every=10_000_000)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b433a302-de7a-4045-b67c-f3ebb3aab794"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Processed 10000000 lines\nProcessed 20000000 lines\nProcessed 30000000 lines\nProcessed 40000000 lines\nProcessed 45840617 lines\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Processed 10000000 lines\nProcessed 20000000 lines\nProcessed 30000000 lines\nProcessed 40000000 lines\nProcessed 45840617 lines\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["!wc -l {test_dataset_path}"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2faffa05-0de3-401f-b7d4-b87714a98a17"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">4585250 /databricks/driver/sync/data/criteo_dataset/criteo_test_dataset.txt\r\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">4585250 /databricks/driver/sync/data/criteo_dataset/criteo_test_dataset.txt\r\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Shuffling\nThe convergence guarantees of SGD rely on the fact that the observations come at random. Hence, shuffling between epochs is important.\n\nFirst result of \"How to shuffle a file that is too big for memory\" on Google: https://stackoverflow.com/a/40814865/2015762\n\nNote that quicker pseudo-shuffling strategies exists, but this fits our \"Big data on your laptop\" problematic."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b524a5dd-b21f-4572-bf9b-6de10e539122"}}},{"cell_type":"code","source":["!awk 'BEGIN{srand();} {printf \"%06d %s\\n\", rand()*1000000, $0;}' /databricks/driver/sync/data/criteo_dataset/criteo_test_dataset.txt | sort -n | cut -c8- > /databricks/driver/sync/data/criteo_dataset/criteo_test_dataset_shuffled.txt\n# We can run it on the train dataset too but let'ss skip it since it is quite long\n# !awk 'BEGIN{srand();} {printf \"%06d %s\\n\", rand()*1000000, $0;}' /databricks/driver/sync/data/criteo_dataset/criteo_train_dataset.txt | sort -n | cut -c8- > /databricks/driver/sync/data/criteo_dataset/criteo_train_dataset_shuffled.txt"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e8546d50-68d4-4f24-abb1-e0c9aa11df96"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Training\nIn order to train a logistic model on chunks of data, we will use scikit-learn `SGDClassifier` (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) and train for its `log` loss with its `partial_fit` method.\nWe can now apply the previous data processing pipeline and add the training to obtain a trained classifier."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d7444e81-90d6-43c5-acf8-68699e77a3dd"}}},{"cell_type":"code","source":["#  To begin with, let's not do any preprocessing and deal with \"ready to use\" continuous features only\ndef preprocess_data(chunk, integer_features, categorical_features):\n    return chunk[integer_features].fillna(-1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5f300552-af45-4ab0-a495-db4ba9a8a827"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["max_training_steps = 10_000\nchunk_size = 1_000\nprint_every = 1000\n\nclassifier = SGDClassifier(loss=\"log\")\n# 1. Read train data by chunks\nreader = pd.read_csv(\n    train_dataset_path, sep=\"\\t\", header=None, names=columns, dtype=col_types, chunksize=chunk_size, \n)\nfor i, chunk in enumerate(reader):\n    # 2. Apply preprocess_data to return the continous features\n    features = preprocess_data(chunk, integer_features, categorical_features)\n    # 3. Train classifier on this chunk  with fit.\n    classifier.partial_fit(features, chunk[\"label\"], classes=[0, 1])\n    # 4. Stop after `max_training_steps`\n    if i > max_training_steps:\n        break\n        \n    if print_every is not None and (i + 1) % print_every == 0:\n        print(i+1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c2fff3fb-3a17-42b0-b5aa-d05ff9632ae7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Testing\nLet's evaluate the performances of the trained classifier. We should iterate over the test dataset and evaluate the labels predicted by the classifier with `roc_auc_score` and `log_loss`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3ccf2390-7b6e-4ec1-b29f-5e3f767e3fbe"}}},{"cell_type":"code","source":["max_testing_steps = 1_000\nchunk_size = 1_000\nprint_every = 100\n\nreader = pd.read_csv(\n    test_dataset_path, sep=\"\\t\", header=None, names=columns, dtype=col_types, chunksize=chunk_size, \n)\n\nroc_auc_scores = []\nlog_losses = []\n# 1. Read test data by chunks\nfor i, chunk in enumerate(reader):\n    # 2. Apply preprocess_data to return the continous features\n    features = preprocess_data(chunk, integer_features, categorical_features)\n    # 3. Predict labels with classifiers\n    label_predictions = classifier.predict_proba(features)[:, 1]\n    # 4. Compute AUC score and Log loss for this chunk\n    roc_auc_scores += [roc_auc_score(chunk[\"label\"], label_predictions)]\n    log_losses += [log_loss(chunk[\"label\"], label_predictions)]\n    \n    if i > max_testing_steps:\n        break\n        \n    if print_every is not None and (i + 1) % print_every == 0:\n        print(i+1)\n\n# 6. Return averaged values of the metrics\nprint(f\"AUC = {np.mean(roc_auc_scores)}\")\nprint(f\"LogLoss = {np.mean(log_losses)}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9a3f8de1-b8aa-41c8-9a46-9c62122da7f9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">100\n200\n300\n400\n500\n600\n700\n800\n900\n1000\nAUC = 0.7614335822071854\nLogLoss = 0.4867119718778749\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">100\n200\n300\n400\n500\n600\n700\n800\n900\n1000\nAUC = 0.7614335822071854\nLogLoss = 0.4867119718778749\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Data preprocessing"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f2c9ec3e-554e-4caf-b9bb-bcec65ed3dba"}}},{"cell_type":"markdown","source":["### Continuous features\nA smart way to deal with continuous features (counting integer features are part of them), consists in transforming them into categorical features through a quantile transformation. To do so we will use scikit-learn KBinsDiscretizer : https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html.\n\nIt can be used as following\n```\ndf = pd.DataFrame({'col_1': np.random.normal(size=1000), 'col_2': np.random.poisson(lam=1, size=1000)})\nbucketizer = KBinsDiscretizer(n_bins=20, encode='ordinal')\nbucketizer.fit(df)\ndf_bucketized = pd.DataFrame(bucketizer.transform(df), columns=[f'{col}_bucketized' for col in df.columns], index=df.index)\nsns.jointplot(data=pd.concat((df, df_bucketized), axis=1), x=\"col_1\", y=\"col_1_bucketized\")\n```"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cacde538-c462-4da5-a5cb-78bbf2e8b624"}}},{"cell_type":"markdown","source":["1. Create a `KBinsDiscretizer` and train it on the first chunk of the dataset\n1. Update `preprocess_data` to add a bucketize step to the training pipeline. What happens if you change the `encode` parameter?\n1. Do not forget to deal with missing values, you do not want to carry on NaNs. You can for example replace them with -1."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e87b6181-a50c-4a25-9269-825927d14df4"}}},{"cell_type":"code","source":["bucketizer = KBinsDiscretizer(n_bins=20) # Try with and without encode='ordinal'\nwith warnings.catch_warnings(record=True):\n    bucketizer.fit(chunk[integer_features].fillna(-1))\n    \ndef bucketize(df, bucketizer):\n    return bucketizer.transform(df.fillna(-1))\n\ndef preprocess_data(chunk, integer_features, categorical_features):\n    return bucketize(chunk[integer_features], bucketizer)\n\npreprocess_data(chunk, integer_features, categorical_features)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6603e270-56e3-4ed9-a6e3-b6b8b70b1e0b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[104]: &lt;1000x166 sparse matrix of type &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39;\n\twith 13000 stored elements in Compressed Sparse Row format&gt;</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[104]: &lt;1000x166 sparse matrix of type &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39;\n\twith 13000 stored elements in Compressed Sparse Row format&gt;</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Categorical features\nFor categorical features we will implement the hashing trick by ourselves. As a quick reminder, for each row\n\n1. Select the categorical features \n1. Create for each feature the string concatenating the feature name and the feature value\n1. Apply a hash function to each of these string and use this value to choose the feature's column index\n1. Store the transformed features in a sparse matrix"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ada99dde-fc5f-41e5-bd37-b7a018e66736"}}},{"cell_type":"code","source":["from sklearn.utils.murmurhash import murmurhash3_bytes_s32\n\ndef hash_string(string, seed=0):\n    return murmurhash3_bytes_s32(string.encode(), seed)\n  \nhash_string('my_feature=my_feature_value')\n# Note, if we were using builtin function hash('my_feature=my_feature_value'), we would have had a different hash value at each run"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ef9557fb-a1d4-4d70-b70c-158be1bc30b4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[106]: 1480568101</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[106]: 1480568101</div>"]}}],"execution_count":0},{"cell_type":"code","source":["hash_space = 2 ** 16\n\nrow = chunk.iloc[0]\ndef get_features_hashes(row, hash_space):\n    # return the list of the hashes values for each categorical feature in the row\n    features_as_string = [f\"{label}={value}\" for label, value in zip(row.index, row.values)]\n    # https://github.com/scikit-learn/scikit-learn/blob/95119c13af77c76e150b753485c662b7c52a41a2/sklearn/feature_extraction/_hashing_fast.pyx#L68\n    return [abs(hash_string(string)) % hash_space for string in features_as_string]\n\nnp.array(get_features_hashes(row, hash_space))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"31886db4-d1db-4a02-a9bd-f752ce68ae0a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[107]: array([26837, 21638, 49088, 37471,  7692, 41062, 24334, 64092,  5751,\n        5424, 40976, 40268, 52632, 11692, 34626, 45899, 20384, 11307,\n       21604, 23634, 61337, 53234, 11512, 22037, 26718, 58424, 45763,\n       10187, 35706, 51356, 29342,  6149, 25889, 53956, 35379, 12896,\n       45210, 53805, 28145, 30177])</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[107]: array([26837, 21638, 49088, 37471,  7692, 41062, 24334, 64092,  5751,\n        5424, 40976, 40268, 52632, 11692, 34626, 45899, 20384, 11307,\n       21604, 23634, 61337, 53234, 11512, 22037, 26718, 58424, 45763,\n       10187, 35706, 51356, 29342,  6149, 25889, 53956, 35379, 12896,\n       45210, 53805, 28145, 30177])</div>"]}}],"execution_count":0},{"cell_type":"code","source":["def transform_with_hashing_trick(df, hash_space):\n    col_indices = df.apply(lambda row: get_features_hashes(row, hash_space), axis=1) \n    row_indices = [\n        [row_index] * len(cols)\n        for row_index, cols in zip(np.arange(len(col_indices)), col_indices)\n    ]\n\n    flat_col_indices = sum(col_indices.values, [])\n    flat_row_indices = sum(row_indices, [])\n    data = np.ones_like(flat_col_indices)\n    # Fill the csr_matrix, using csr_matrix((data, (row_ind, col_ind)), [shape=(M, N)]) constructor\n    # See https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html\n    return csr_matrix((data, (flat_row_indices, flat_col_indices)), shape=(len(df), hash_space), dtype=float)\n  \ntransform_with_hashing_trick(chunk[categorical_features], hash_space)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2c9c09dd-41fe-4fa5-93bb-b7c0afaabb0c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[108]: &lt;1000x65536 sparse matrix of type &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39;\n\twith 25998 stored elements in Compressed Sparse Row format&gt;</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[108]: &lt;1000x65536 sparse matrix of type &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39;\n\twith 25998 stored elements in Compressed Sparse Row format&gt;</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Actually, the hashing trick is well known and already implemented in scikit-learn FeatureHasher: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.FeatureHasher.html\n\nIt can be used as following\n```\ndf = pd.DataFrame({'col_1': np.random.choice(['a', 'b', 'c'], size=100), 'col_2': np.random.poisson(size=100)})\nhasher = FeatureHasher(n_features=2**16, input_type=\"dict\")\nhasher.transform((row._asdict() for row in df.itertuples(index=False)))\n```\nAgain, you will probably want to ensure you get rid of the NaNs. What value could you set for these?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0c520c13-7534-4fad-9bf2-2f88c15cd8f6"}}},{"cell_type":"code","source":["hasher = FeatureHasher(n_features=hash_space, input_type=\"dict\")\n\ndef feature_hashing(df, hasher):\n    # apply hasher.transorm to rows of df\n    return hasher.transform((row._asdict() for row in df.fillna(\"nan\").itertuples(index=False)))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ba5b0a8e-722b-47e2-a46f-b9a9dce7c4d3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["We can compare their speed"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f90abde0-a667-4e34-af5a-282b17b232f2"}}},{"cell_type":"code","source":["%timeit transform_with_hashing_trick(chunk[categorical_features], hash_space)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6aee4d29-3d84-4f2a-b387-ec233412213b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">186 ms ± 2.64 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">186 ms ± 2.64 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%timeit feature_hashing(chunk[categorical_features], hasher)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"22633b92-95dd-4fda-8580-f11bf7a2f102"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">28.3 ms ± 1.22 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">28.3 ms ± 1.22 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Actually we have used exactly the same implementation as sklearn.\nSee https://github.com/scikit-learn/scikit-learn/blob/95119c13af77c76e150b753485c662b7c52a41a2/sklearn/feature_extraction/_hashing_fast.pyx#L68"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6a84b01f-fc67-4f3d-90ba-c5a5201d9e84"}}},{"cell_type":"code","source":["hash_space = 20\ndf = chunk[categorical_features].head(5)\nprint('Custom implementation')\nprint(transform_with_hashing_trick(df, hash_space).toarray())\nhasher = FeatureHasher(n_features=hash_space, input_type=\"dict\", alternate_sign=False)\nprint('sklearn implementation')\nprint(feature_hashing(df, hasher).toarray())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"850e936a-8c87-43c8-b311-584e19f464d9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Custom implementation\n[[1. 2. 3. 1. 2. 1. 1. 2. 1. 2. 0. 2. 1. 1. 1. 0. 2. 1. 2. 0.]\n [4. 1. 2. 3. 1. 0. 0. 0. 1. 1. 1. 2. 1. 0. 3. 0. 0. 1. 2. 3.]\n [2. 1. 0. 2. 2. 0. 0. 1. 1. 0. 3. 1. 2. 1. 2. 2. 1. 1. 3. 1.]\n [0. 3. 2. 4. 1. 1. 3. 0. 1. 1. 1. 2. 2. 1. 0. 2. 0. 1. 0. 1.]\n [2. 1. 3. 2. 1. 2. 2. 0. 1. 2. 2. 1. 1. 0. 1. 1. 1. 1. 0. 2.]]\nsklearn implementation\n[[1. 2. 3. 1. 2. 1. 1. 2. 1. 2. 0. 2. 1. 1. 1. 0. 2. 1. 2. 0.]\n [4. 1. 2. 3. 1. 0. 0. 0. 1. 1. 1. 2. 1. 0. 3. 0. 0. 1. 2. 3.]\n [2. 1. 0. 2. 2. 0. 0. 1. 1. 0. 3. 1. 2. 1. 2. 2. 1. 1. 3. 1.]\n [0. 3. 2. 4. 1. 1. 3. 0. 1. 1. 1. 2. 2. 1. 0. 2. 0. 1. 0. 1.]\n [2. 1. 3. 2. 1. 2. 2. 0. 1. 2. 2. 1. 1. 0. 1. 1. 1. 1. 0. 2.]]\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Custom implementation\n[[1. 2. 3. 1. 2. 1. 1. 2. 1. 2. 0. 2. 1. 1. 1. 0. 2. 1. 2. 0.]\n [4. 1. 2. 3. 1. 0. 0. 0. 1. 1. 1. 2. 1. 0. 3. 0. 0. 1. 2. 3.]\n [2. 1. 0. 2. 2. 0. 0. 1. 1. 0. 3. 1. 2. 1. 2. 2. 1. 1. 3. 1.]\n [0. 3. 2. 4. 1. 1. 3. 0. 1. 1. 1. 2. 2. 1. 0. 2. 0. 1. 0. 1.]\n [2. 1. 3. 2. 1. 2. 2. 0. 1. 2. 2. 1. 1. 0. 1. 1. 1. 1. 0. 2.]]\nsklearn implementation\n[[1. 2. 3. 1. 2. 1. 1. 2. 1. 2. 0. 2. 1. 1. 1. 0. 2. 1. 2. 0.]\n [4. 1. 2. 3. 1. 0. 0. 0. 1. 1. 1. 2. 1. 0. 3. 0. 0. 1. 2. 3.]\n [2. 1. 0. 2. 2. 0. 0. 1. 1. 0. 3. 1. 2. 1. 2. 2. 1. 1. 3. 1.]\n [0. 3. 2. 4. 1. 1. 3. 0. 1. 1. 1. 2. 2. 1. 0. 2. 0. 1. 0. 1.]\n [2. 1. 3. 2. 1. 2. 2. 0. 1. 2. 2. 1. 1. 0. 1. 1. 1. 1. 0. 2.]]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Let's improve our previous pipeline and apply the hashing trick to the categorical features **and** to the bucketized continuous features (have a look at `pd.concat`)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4598f259-ae84-457e-b565-1fbccd4359e9"}}},{"cell_type":"code","source":["hash_space = 2 ** 20\n\nhasher = FeatureHasher(n_features=hash_space, input_type=\"dict\")\nbucketizer = KBinsDiscretizer(n_bins=20, encode='ordinal')\nwith warnings.catch_warnings(record=True):\n    bucketizer.fit(chunk[integer_features].fillna(-1))\n\ndef bucketize(df, bucketizer):\n    return pd.DataFrame(bucketizer.transform(df.fillna(-1)), columns=df.columns, index=df.index)\n\ndef preprocess_data(df, integer_features, categorical_features):\n    bucketized_integer_features_df = bucketize(chunk[integer_features], bucketizer)\n    categorical_features_df = pd.concat([chunk[categorical_features], bucketized_integer_features_df], axis=1)\n    return feature_hashing(categorical_features_df, hasher)\n\npreprocess_data(chunk, integer_features, categorical_features)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"51d49529-7ca5-4f67-b16e-b8c347ac29b3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[121]: &lt;1000x1048576 sparse matrix of type &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39;\n\twith 36135 stored elements in Compressed Sparse Row format&gt;</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[121]: &lt;1000x1048576 sparse matrix of type &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39;\n\twith 36135 stored elements in Compressed Sparse Row format&gt;</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Going further with the hashing trick:\n1. How could you implement cross features ?\n1. If you are too afraid of collisions, try to hash each categorical feature to several locations.\n\nTry with FeatureHasher and your custom implementation and see what is the most efficient."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"157a858a-544e-4219-86b6-4b3423310e16"}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"da65498b-985a-42ce-863d-acea33fa3f09"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Local online learning - after 1st session","dashboards":[],"language":"python","widgets":{},"notebookOrigID":1919988149413991}},"nbformat":4,"nbformat_minor":0}
