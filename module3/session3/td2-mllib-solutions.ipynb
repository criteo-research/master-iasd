{"cells":[{"cell_type":"markdown","source":["# Presentation\nIn this workshop we will discover Mllib features, and apply them on the titanic dataset.\n\nWe will try to predict passenger survival rate based on a few features, with a logistic regression model."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"51cf46e8-e114-407b-bf24-fef10f9aea04"}}},{"cell_type":"markdown","source":["## Load dataset\nWe need to download dataset and put it inside HDFS."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"56b3941f-b4d2-465e-b2a9-edd7eb069b66"}}},{"cell_type":"code","source":["# download dataset, make sure it is available on your gateway\nimport urllib\nurl = \"https://www.dropbox.com/s/uf1pfvrmbrmqoqz/titanic-passengers.csv?dl=1\"\nurllib.request.urlretrieve(url, \"titanic.csv\")\ndbutils.fs.ls(\"file:/databricks/driver/\")\n\n# move the dataset to the file storage\ndbutils.fs.mv(\"file:/databricks/driver/titanic.csv\", \"dbfs:/titanic.csv\", recurse=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"117f3fe7-056b-477c-8761-43c47a4680e6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Tools of the trade\nWe need a few imports to learn some model with MLLib."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2bc1d6d0-4ec8-44ef-bc8d-7b840e4a0d89"}}},{"cell_type":"code","source":["from pyspark.sql import functions as F # you already know this one ! need it whenever you want to transform columns\nfrom pyspark.ml.feature import *       # this package contains most of mllib feature engineering tools\nfrom pyspark.ml import Pipeline        # pipeline is used to combine features"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"55e21102-1244-482c-afcb-5aabc90c3dc3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Question 0\nLoad the dataset.\n\nMake sure the remainder of the schema is correct."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ded2ba2e-2331-4d83-9046-cef307969cd3"}}},{"cell_type":"code","source":["df = spark.read.format(\"csv\").load(\"dbfs:/titanic.csv\", header=True, delimiter=\";\", inferSchema=True)\ndf.printSchema()\ndisplay(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b13970e3-3b8c-4f32-929d-fb11f0caf844"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["train, test = df.cache().randomSplit([0.9, 0.1], seed=12345)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9fbd51b0-33aa-4331-a26d-e7c92aaeb6de"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Question 1\nOn training set, fit a model that predicts passenger survival probability, function of ticket price.\n\nYou will need to convert survived column in 0/1 to pass it to the logistic regression. Transform it with StringIndexer.\n\nUse a pipeline ending with a logistic regression.\n\nCompute model AUC on validation set.\n\nDocumentation:\n- https://spark.apache.org/docs/latest/ml-classification-regression.html#binomial-logistic-regression\n- https://spark.apache.org/docs/latest/ml-pipeline.html#example-pipeline\n- https://spark.apache.org/docs/latest/mllib-evaluation-metrics.html#binary-classification"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"463001f6-503d-4ab9-8654-f31637582886"}}},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\n\nstages=[]\nstages += [VectorAssembler(inputCols=[\"Fare\"], outputCol=\"vec_fare\")]\nstages += [StringIndexer(inputCol=\"Survived\", outputCol=\"int_survived\")]\nstages += [LogisticRegression(featuresCol=\"vec_fare\", labelCol=\"int_survived\")]\npipeline = Pipeline(stages=stages)\n\npredictor = pipeline.fit(train)\ndf_pred = predictor.transform(test)\n\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nevaluator = BinaryClassificationEvaluator(labelCol=\"target\", rawPredictionCol=\"prediction\", metricName='areaUnderROC')\npredictionAndTarget = df_pred.select(F.col(\"int_survived\").alias(\"target\"), \"prediction\")\nauc = evaluator.evaluate(predictionAndTarget)\ndisplay(df_pred)\nprint(auc)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"06ce7c3d-3d2e-4bde-9560-ed9171bf58a0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Question 2\nWe will do a lots of feature engineering now and we don't want you to copy-paste code all-way long.\n\nWrite the following function:\n\nInputs:\n- pipeline\n- training set\n- validation set\n\nOutputs:\n- auc\n- transformed dataset (with prediction)\n\nMake sure it returns on previous pipeline."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4579a58c-9e9b-4f9a-bd32-5feecd3dd41d"}}},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\ndef analyze(pipeline, train, test):\n  predictor = pipeline.fit(train)\n  df_pred = predictor.transform(test)\n  evaluator = BinaryClassificationEvaluator(labelCol=\"target\", rawPredictionCol=\"prediction\", metricName='areaUnderROC')\n  predictionAndTarget = df_pred.select(F.col(\"int_survived\").alias(\"target\"), \"prediction\")\n  auc = evaluator.evaluate(predictionAndTarget)\n  return (auc, df_pred)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f11a5d25-2e33-4200-b447-e987b7e08878"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["(auc, pred) = analyze(pipeline, train, test)\nprint(auc)\ndisplay(pred)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"26583cd3-baea-4ec8-81ca-d4fca488d933"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Question 3\nRelying on raw continuous feature may be a bit rough.\nWe can try to bucketize numeric feature in five buckets instead."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b03803ba-1430-4794-8f51-f4db5801fdbb"}}},{"cell_type":"code","source":["stages=[]\n\nstages += [QuantileDiscretizer(inputCol=\"Fare\", outputCol=\"buk_fare\", numBuckets=5)]\n\n#or:\n#buckets = [float(\"-inf\")]+[10*i for i in range(0,5)]+[float(\"inf\")]\n#stages += [Bucketizer(splits=buckets, inputCol=\"Fare\", outputCol=\"buk_fare\")]\n\nstages += [OneHotEncoder(inputCol=\"buk_fare\", outputCol=\"vec_fare\")]\nstages += [StringIndexer(inputCol=\"Survived\", outputCol=\"int_survived\")]\nstages += [LogisticRegression(featuresCol=\"vec_fare\", labelCol=\"int_survived\")]\npipeline = Pipeline(stages=stages)\n(auc, pred) = analyze(pipeline, train, test)\nprint(auc)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"87482d50-c46e-45e7-84e5-44bbbce657af"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Question 4\nWhy don't you try to rely on other numerical features now ?\n\nYou can try to leverage 'Age', and maybe 'PassengerId' while we're at it.\n\nIs it better ?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a83bf019-a813-4107-8c4a-493ca86046a1"}}},{"cell_type":"code","source":["stages=[]\nstages += [QuantileDiscretizer(inputCol=\"PassengerId\", outputCol=\"buk_passengerid\", numBuckets=5)]\nstages += [OneHotEncoder(inputCol=\"buk_passengerid\", outputCol=\"vec_passengerid\")]\nstages += [QuantileDiscretizer(inputCol=\"Fare\", outputCol=\"buk_fare\", numBuckets=5)]\nstages += [OneHotEncoder(inputCol=\"buk_fare\", outputCol=\"vec_fare\")]\n\nstages += [StringIndexer(inputCol=\"Survived\", outputCol=\"int_survived\")]\nstages += [VectorAssembler(inputCols=[\"vec_passengerid\", \"vec_fare\"], outputCol=\"features\")]\nstages += [LogisticRegression(featuresCol=\"features\", labelCol=\"int_survived\")]\npipeline = Pipeline(stages=stages)\n(auc, df_pred) = analyze(pipeline, train, test)\nprint(auc)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b390460e-373a-413e-afe1-7544bf4ef83c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Question 5\nWe should try to use categorial features.\n\nRemember, spark just understands vectors. So you need to convert categories in vectors with OneHotEncoder.\n\nTry several categories and identify what works."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f3cd8a2b-ab7b-4ab9-a1cf-29b7ecde5f79"}}},{"cell_type":"code","source":["categories = [\"Pclass\", \"SibSp\", \"Parch\"]\nfor col_name in categories:\n  stages=[]\n  stages += [OneHotEncoder(inputCol=col_name, outputCol=f\"vec_{col_name}\")]\n  stages += [StringIndexer(inputCol=\"Survived\", outputCol=\"int_survived\")]\n  stages += [LogisticRegression(featuresCol=f\"vec_{col_name}\", labelCol=\"int_survived\")]\n  pipeline = Pipeline(stages=stages)\n  (auc,pref) = analyze(pipeline, train, test)\n  print(f\"{col_name} : {auc}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"27703893-d86a-4127-b6d9-afbf306bc1d4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Sex is not numeric, we need to convert it before one-hot-encoding it !"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c8633f54-965a-463d-94c3-a7bdfee5081a"}}},{"cell_type":"code","source":["stages=[]\nstages += [StringIndexer(inputCol=\"Sex\", outputCol=\"int_sex\")]\nstages += [OneHotEncoder(inputCol=\"int_sex\", outputCol=\"vec_sex\")]\nstages += [StringIndexer(inputCol=\"Survived\", outputCol=\"int_survived\")]\nstages += [LogisticRegression(featuresCol=\"vec_sex\", labelCol=\"int_survived\")]\npipeline = Pipeline(stages=stages)\n(auc,pref) = analyze(pipeline, train, test)\nprint(f\"{col_name} : {auc}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"521f533a-9c49-4cee-ba30-d880c13306a7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Question 6\n\nTry to:\n- rely on name feature\n- cross features. E.g., try to use features like : passenger is male and passenger is older than 30 years.\n- use feature hashing"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1427b306-351d-42b7-afa2-7f54664141f8"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Titanic + MLLib (solution)","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":323843935193549}},"nbformat":4,"nbformat_minor":0}
