{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Matrix Factorization\n",
        "\n",
        "We will experiment with the recent MovieLens 25M Dataset and build a recommender system using two approaches:\n",
        "* Factorizing the user-item matrix using Spark ALS implementation\n",
        "* Factorizing the item-item PMI maatrix using randomized SVD\n",
        "\n",
        "In both settings we will index the item embeddings and inspect their quality using KNN queries."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "ec58202f-3dde-4483-b569-f93f1ab4a8c7"
        },
        "id": "zQtIoL9MtSmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!curl -O https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OttKOqUv4KUK",
        "outputId": "ea9ef4ba-0014-41cf-aef3-de85bbfd4797"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  287M  100  287M    0     0   187M      0  0:00:01  0:00:01 --:--:--  187M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "-QsPG2H44M-A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext, SparkConf, StorageLevel\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql import Window\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "cD0tjpDGdy2f"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf = (\n",
        "    SparkConf()\n",
        "    .set('spark.ui.port', '4050')\n",
        "    .set(\"spark.driver.memory\", \"16g\")\n",
        "    .set('spark.driver.maxResultsSize', '8g')\n",
        ")\n",
        "sc = SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.master('local[*]').getOrCreate()\n",
        "ss = spark"
      ],
      "metadata": {
        "id": "DEZXjULX4OUd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the dataset"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "930121a6-31fe-4b95-8459-4fb22caf15e5"
        },
        "id": "WXemqj5LtSma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://files.grouplens.org/datasets/movielens/ml-25m.zip\n",
        "!unzip ml-25m"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "f2fa6086-66c5-4421-997c-3abc0bc79ab2"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99rSuu40tSmb",
        "outputId": "4c966b28-c815-4c5c-856b-336b1cf603f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-20 09:20:17--  http://files.grouplens.org/datasets/movielens/ml-25m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 261978986 (250M) [application/zip]\n",
            "Saving to: ‘ml-25m.zip’\n",
            "\n",
            "ml-25m.zip          100%[===================>] 249.84M  78.2MB/s    in 3.4s    \n",
            "\n",
            "2022-05-20 09:20:21 (73.2 MB/s) - ‘ml-25m.zip’ saved [261978986/261978986]\n",
            "\n",
            "Archive:  ml-25m.zip\n",
            "   creating: ml-25m/\n",
            "  inflating: ml-25m/tags.csv         \n",
            "  inflating: ml-25m/links.csv        \n",
            "  inflating: ml-25m/README.txt       \n",
            "  inflating: ml-25m/ratings.csv      \n",
            "  inflating: ml-25m/genome-tags.csv  \n",
            "  inflating: ml-25m/genome-scores.csv  \n",
            "  inflating: ml-25m/movies.csv       \n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the ratings dataset"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "83dc87e1-4575-41fb-b9b9-53515664b2ac"
        },
        "id": "g0QxsM57tSmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df = spark.read.csv('ml-25m/movies.csv', header=True, inferSchema=True).cache()\n",
        "ratings_df = spark.read.csv('ml-25m/ratings.csv', header=True, inferSchema=True)"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "30cde39c-8089-4c5c-9b95-347a8b3414b0"
        },
        "id": "9K-dP8DLtSmd"
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1 : Alternating least squares"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "63c24520-7d86-48bc-8abe-c38f26bf1bc6"
        },
        "id": "354N1dKjtSma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split the dataset\n",
        "We want to randomly split the dataset into train and test parts"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "9638b534-2471-4f74-8c9c-df471a6dbc43"
        },
        "id": "LGPmUmNPtSmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(training_df, validation_df) = ratings_df.randomSplit([0.8, 0.2])"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "099d08ee-00b8-496e-a91e-240c18f31a5d"
        },
        "id": "w8IVHN0otSmd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "training_df.count()"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "9dc8e22b-5a6b-4a23-ad94-4bf1ed8adfac"
        },
        "id": "fj8XCO7etSme"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build ALS model\n",
        "Using the Spark ALS implementation described here https://spark.apache.org/docs/2.2.0/ml-collaborative-filtering.html\n",
        "Build a model using the ml-25m dataset.\n",
        "\n",
        "How long does the training take, change the rank (i.e. the dimension of the vectors) from 10 to 20. How does that affect training speed ?"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "b7b13148-8e7e-46f1-b856-3727dd2c7021"
        },
        "id": "2_MnMK84tSme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.recommendation import ALS\n",
        "import time\n",
        "\n",
        "ranks = [10,15,20]\n",
        "models = []\n",
        "training_time = []\n",
        "\n",
        "for rank in ranks:\n",
        "  start_time = time.time()\n",
        "  als = ALS(rank=rank, maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
        "  model = als.fit(training_df)\n",
        "  models.append(model)\n",
        "  training_time.append(time.time() - start_time)"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "b3fd44e1-0529-4af3-919f-3118b6e30d13"
        },
        "id": "kT1hZW4ktSmf",
        "outputId": "c4c176b6-00b0-4f29-8728-d7be2929923a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "data": "",
              "errorSummary": "",
              "metadata": {},
              "errorTraceType": null,
              "type": "ipynbError",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import plot\n",
        "%matplotlib inline\n",
        "plot(ranks, training_time)\n",
        "\n",
        "# processing time seems linear as long as we don't have memory issues to deal-with."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "2d712aad-f474-441f-8236-8a94e6cda128"
        },
        "id": "gY98EXpHtSmf",
        "outputId": "4db29157-d574-4c2f-a4e3-61ca9b621d1d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "data": "",
              "errorSummary": "",
              "metadata": {},
              "errorTraceType": null,
              "type": "ipynbError",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation\n",
        "Using the code described in the Spark documentation, evaluate how good your model is doing on the test set.\n",
        "The goal is to predict the held out ratings.\n",
        "A good metric could be RMSE or MAE."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "3342dd06-1737-43ec-bef3-c185c601bb24"
        },
        "id": "j1kzCUA6tSmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "predictions = model.transform(validation_df)\n",
        "evaluator = RegressionEvaluator(metricName=\"mae\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "mae = evaluator.evaluate(predictions)\n",
        "print(f\"MAE = {mae}\")"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "49bbd4e6-7c06-4929-9c97-cd56f7c7bcda"
        },
        "id": "LvSzD8lytSmf",
        "outputId": "4cff394e-0065-4885-d990-909a7c419274"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "data": "",
              "errorSummary": "",
              "metadata": {},
              "errorTraceType": null,
              "type": "ipynbError",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspecting the results\n",
        "\n",
        "Retrieve the movie vectors from the learned model object (the property is called itemFactors).\n",
        "and `collect` all these vectors in a list."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "9de1257d-ea6d-4833-ac47-79311f0c0f8a"
        },
        "id": "VJ9XHHH8tSmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie_vectors_df = (\n",
        "    model.itemFactors\n",
        "    .join(movies_df.withColumnRenamed('movieId', 'id'), 'id')\n",
        "    .select('title', 'features')\n",
        ")"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "7d9e5482-54ff-4950-9b8d-4d889c64dd7b"
        },
        "id": "acIfjB3BtSmg",
        "outputId": "10a62969-3cae-4295-e856-c253a9461f52"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "data": "",
              "errorSummary": "",
              "metadata": {},
              "errorTraceType": null,
              "type": "ipynbError",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to create a dictionary mapping the movieId to it's title to ease the inspection. \n",
        "Load the `movies.csv` file using pyspark or pandas and create a `dict` movieId -> title."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "6f67edcb-fc63-47b8-ae6d-ec1c1c6c1e42"
        },
        "id": "sPR6YiWFtSmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie_vect_dict = {r['title'] : r['features'] for r in movie_vectors_df.collect()}"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "d018601f-236f-4777-8a93-6846f5ac9ab7"
        },
        "id": "Pzfc0p2GtSmg",
        "outputId": "05a05005-79e1-451d-e930-5c0ab0b285d7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "data": "",
              "errorSummary": "",
              "metadata": {},
              "errorTraceType": null,
              "type": "ipynbError",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Nearest neighbours\n",
        "\n",
        "Pick a few movies, and for each of them, find-out the top 5 nearest neighbours. This is very similar to an optional question of the PLSA project..."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "89e7fa17-0f14-42ae-9bd7-7894dbbc6069"
        },
        "id": "gLBP389ItSmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "title_vector_array = movie_vectors_df.collect()\n",
        "titles = [r['title'] for r in title_vector_array]\n",
        "vectors = [r['features'] for r in title_vector_array]"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "acefd735-d0a6-454e-811a-8ccf54092731"
        },
        "id": "-73BEkJPtSmg",
        "outputId": "80288d23-a9df-4316-ea1f-6fd7716c536f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "data": "",
              "errorSummary": "",
              "metadata": {},
              "errorTraceType": null,
              "type": "ipynbError",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from numpy import linalg as LA\n",
        "import heapq\n",
        "# naive knn with queue, using numpy to batch vector operations\n",
        "def knn(query, k, titles, vectors):\n",
        "  start_time = time.time()\n",
        "  nb_movies = len(titles)\n",
        "  diff = numpy.array(vectors) - numpy.array(query)\n",
        "  distances = LA.norm(diff, axis=1)\n",
        "  indices = heapq.nlargest(k, range(0, nb_movies), key=lambda x: -distances[x])\n",
        "  ret = [(titles[i], distances[i]) for i in indices]\n",
        "  print(f\"{time.time() - start_time}\")\n",
        "  return ret"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "c22a620d-a7d7-46d6-ab38-fb6556e0ce7c"
        },
        "id": "sKiNVq1TtSmg",
        "outputId": "d20e7dbb-748a-416d-8773-b510850670e4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "data": "",
              "errorSummary": "",
              "metadata": {},
              "errorTraceType": null,
              "type": "ipynbError",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze(i):\n",
        "  print(f\"Query title : {titles[i]}\")\n",
        "  query_vec = vectors[i]\n",
        "  ret = knn(query_vec, 10, titles, vectors)\n",
        "  for res in ret:\n",
        "    print(res)"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "6afe8993-2f1a-4bee-ad77-ccee37bda30a"
        },
        "id": "DqFftYiatSmh",
        "outputId": "b5bf15ce-86d2-4e59-d7f8-a3104fda2e41"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "data": "",
              "errorSummary": "",
              "metadata": {},
              "errorTraceType": null,
              "type": "ipynbError",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "analyze(4)"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "b66d2c26-8ab1-4039-b1bd-4db8119fe990"
        },
        "id": "otJnYTJqtSmh",
        "outputId": "4cfed176-69de-48ea-d525-a5fb282ea78a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "data": "",
              "errorSummary": "",
              "metadata": {},
              "errorTraceType": null,
              "type": "ipynbError",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2 : PMI and RSVD"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "0ec9dd97-3a51-4663-9c7a-5c046daf94bf"
        },
        "id": "uafsh1r1tSmh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We now are going to factorize the item-item PMI matrix using randomized SVD."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "6a498b1f-c395-429d-9a32-7ce55ca8e470"
        },
        "id": "Lg4PQQ0gtSmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Size estimation\n",
        "\n",
        "Let's first estimate the size of the matrix we are about to build.\n",
        "\n",
        "Reminder : we will generate the co-occurence matrix $C$ from all the pairs of\n",
        "movies that we find in users ratings. \n",
        "This matrix can be big.\n",
        "\n",
        "Namely, if a user has rated movies `(1, 2, 3, 4)`, we will generate 6 pairs :\n",
        "`(1, 2), (1, 3), (2, 3), (1, 4), (2, 4), (3, 4)`.\n",
        "\n",
        "Formally, if a user has rated $n$ movies, he will generate `......` pairs. We should be careful of users that have rated a lot of movies.\n"
      ],
      "metadata": {
        "id": "3li_rZyKaeCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def number_of_pairs_to_be_generated(ratings_df):\n",
        "  ratings_count_by_user_df = (\n",
        "      ratings_df\n",
        "      .groupby('userId')\n",
        "      .agg(F.count('*').alias('count'))\n",
        "      .sort(F.col('count').desc())\n",
        "  )\n",
        "\n",
        "  return int((\n",
        "      ratings_count_by_user_df\n",
        "     .withColumn(\"n_pairs\", # TODO #)\n",
        "     .select(F.sum(\"n_pairs\"))\n",
        "  ).collect()[0][\"sum(n_pairs)\"])\n",
        "\n",
        "print(\n",
        "    f\"Number of positive ratings : {ratings_df.count():,}\"\n",
        "    f\", that should generate {number_of_pairs_to_be_generated(ratings_df):,} pairs\"\n",
        ")"
      ],
      "metadata": {
        "id": "ApboPulBoj8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Keep positive interactions"
      ],
      "metadata": {
        "id": "hh10FcIMcwsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Yk-BDnTxcwCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Keep meaningful movies\n",
        "\n",
        "We will keep only movies having a sufficient amount of positive ratings.\n",
        "First, that will make the computations lighter, second, it will prevent us from\n",
        "computing embeddings for movies we have very little information on."
      ],
      "metadata": {
        "id": "iDNVQHyuc2Tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oDkBao_Vac5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "g1XjLHxQdrNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6EeY8bpNpWpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SELA1CoKpsMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Limit the number of pairs\n",
        "\n",
        "We have way less movies but still almost all ratings and a lot of pairs ! "
      ],
      "metadata": {
        "id": "FGZ3pTXbp18Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gWtFR3_dp9vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "d30053fe-cdd2-4b81-8ff1-4da04b63c693"
        },
        "id": "2o0YL4jhtSmi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lrJRYCr3CAek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the PMI matrix"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "943f025b-c703-483e-a0b1-554964f69a09"
        },
        "id": "vtq6mrJttSmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reminder, the PMI matrix writes\n",
        "$$\n",
        "PMI(i, j) = \\log\\left(\\frac{p(i, j)}{p(i)p(j)}\\right)\n",
        "$$\n",
        "that we estimate with\n",
        "$$\n",
        "\\widehat{PMI}(i, j) = \\log\\left(\\frac{C_{i, j} \\cdot n}{C_i \\cdot  C_j}\\right)\n",
        "$$\n",
        "where\n",
        "* $C_{i, j}$ is the number of pairs (i, j) (i.e. the number of users that have\n",
        "  given a positive feedback for both movie i and movie j.\n",
        "* $C_{i}$ is total the number of pairs containing i\n",
        "* $C_{j}$ is total the number of pairs containing j\n",
        "* $n$ is the total number of pairs"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "b11143da-b1f3-443b-bb73-f345126ee5d4"
        },
        "id": "FmnSc0cltSmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 1 : compute co-occurence matrix $C_{i,j}$"
      ],
      "metadata": {
        "id": "L9lOgHjKr_r7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "90473310-1c36-4da2-b7d4-082166991e40"
        },
        "id": "IpNTjRR7tSmi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qH7it8PiE73U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2 : Compute total number of pairs per movies $C_i$, $C_j$"
      ],
      "metadata": {
        "id": "KQjYzJMfsfi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vQ6SqUTf98nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3 : compute $\\widehat{PMI}(i, j)$\n",
        "\n",
        "Using the movie counts and the pair counts, compute the PMI dataframe."
      ],
      "metadata": {
        "id": "QybMF5ktt2CG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vp6142sLOOnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8zR8QIuKqXUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Factorizing the PMI matrix with RSVD"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "6ae3d2c4-8142-41b2-b44f-e4653e480ed7"
        },
        "id": "EMZ2KOlrtSmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we need to create a mapping between movie ids and position in the matrix that we call vocabulary."
      ],
      "metadata": {
        "id": "9ndJ7PF_uv8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_ordering_window = Window().orderBy(F.col(\"count\").desc())\n",
        "vocabulary_df = movie_counts_df.select(\n",
        "    \"movieId\",\n",
        "    (F.row_number().over(count_ordering_window) - F.lit(1)).alias(\"index\"),  # row number starts at 1\n",
        ").cache()\n",
        "\n",
        "vocabulary_df.show(3)"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "9f7ca07d-9fdc-4608-97fd-bc001ce33b75"
        },
        "id": "dw_V8nwutSmi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to build a scipy sparse matrix from the PMI dataframe. \n",
        "Thanks to our filtering, it is small enough to be collected into memory.\n",
        "\n",
        "Still this might take a minute or two."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "632c1d5f-eae1-4c24-b710-a1243abb2822"
        },
        "id": "OkBUxdeKtSmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "pmi_pdf = (\n",
        "    pmi_df\n",
        "    .join(vocabulary_df.withColumnRenamed(\"movieId\", \"movieId1\"), on=\"movieId1\")\n",
        "    .withColumnRenamed(\"index\", \"i\")\n",
        "    .join(vocabulary_df.withColumnRenamed(\"movieId\", \"movieId2\"), on=\"movieId2\")\n",
        "    .withColumnRenamed(\"index\", \"j\")\n",
        "    .select(\"i\", \"j\", \"pmi\")\n",
        ").toPandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-JyweESIX32",
        "outputId": "b5aede64-c650-4cab-c9c0-cbe0b4670145"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 40 s, sys: 3.24 s, total: 43.2 s\n",
            "Wall time: 1min 2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this i, j, value representation of the PMI matrix, you can create a scipy sparse matrix (prefer [coo format](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html))"
      ],
      "metadata": {
        "id": "-74HE_xN29T7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "D5wxcYtMJW0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the scikit-learn implementation of SVD https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html to factorize the PMI matrix. It uses the randomized SVD algorithm presented as a default."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "7bb52455-55f5-4d0a-8256-56a44a67e598"
        },
        "id": "nll_XSZqtSmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "74999f03-2bb9-4702-b542-023f2829a00a"
        },
        "id": "ln1rUKwXtSmi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Faiss Index"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "34a5998d-9e80-46d8-9040-df5655ceecf7"
        },
        "id": "N20TIdZ1tSmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's install faiss-cpu, and create an index from these vectors. Query the index like what we have done previously."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "e8e57ed4-fb78-40c9-8db0-f25503f58d3a"
        },
        "id": "jIjJf1QvtSmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0qabzMfKLwr",
        "outputId": "83725b62-2493-4237-d272-1c960c81dbc1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 8.6 MB 4.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create faiss index\n",
        "import faiss\n",
        "\n",
        "movie_embeddings = svd.components_.transpose().astype('float32')\n",
        "index = faiss.IndexFlatIP(movie_embeddings.shape[1])\n",
        "index.add(movie_embeddings)"
      ],
      "metadata": {
        "id": "aiBsRTbkKRBb"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inner_product, neighbors = index.search(movie_embeddings[0].reshape(1, -1), 5)\n",
        "pd.DataFrame({\"neigbors\": neighbors[0], \"inner product\": inner_product[0]})"
      ],
      "metadata": {
        "id": "aa-IQPuD0CqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "62pqCHdlK9Bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "591lZUCRKcdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ym8TdzsaSqxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xe4YTj5iSrnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cjEOt1CaS2gy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "version": "3.7.4",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "application/vnd.databricks.v1+notebook": {
      "notebookName": "Matrix Factorization Part 1 + 2",
      "dashboards": [],
      "notebookMetadata": {
        "pythonIndentUnit": 2
      },
      "language": "python",
      "widgets": {},
      "notebookOrigID": 3894196550542310
    },
    "colab": {
      "name": "td4-part2-matrix-factorization-questions.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "354N1dKjtSma"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}