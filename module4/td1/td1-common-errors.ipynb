{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMVnps0GeomdJX8uegtY6Sm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Installation of Java, Spark with Hadoop and PySpark"],"metadata":{"id":"KagDYyGRU4dT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FdbyCcVfUc43"},"outputs":[],"source":["!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!curl -O https://dlcdn.apache.org/spark/spark-3.2.3/spark-3.2.3-bin-hadoop3.2.tgz\n","!tar xf spark-3.2.3-bin-hadoop3.2.tgz\n","!pip install -q findspark"]},{"cell_type":"markdown","source":["Environment variables and Import"],"metadata":{"id":"oxQ02EbEVKOH"}},{"cell_type":"code","source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.3-bin-hadoop3.2\""],"metadata":{"id":"sncWA4DIUzEy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import findspark\n","findspark.init()\n","import pyspark\n","from pyspark.sql import SparkSession\n","from pyspark import SparkContext, SparkConf\n","\n","conf = SparkConf().set('spark.ui.port', '4050')\n","sc = SparkContext(conf=conf)\n","spark = SparkSession.builder.master('local[*]').getOrCreate()"],"metadata":{"id":"fxV6Tw-9U1gj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","%matplotlib inline"],"metadata":{"id":"RIY90IyhU3Kr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spark"],"metadata":{"id":"xbszNBgiVCv2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"Oe5o3Rb5XmG_"}},{"cell_type":"markdown","source":["# Versionning"],"metadata":{"id":"mwzsMYXzZkmV"}},{"cell_type":"code","source":["!python --version"],"metadata":{"id":"J8tOs4PKZrg6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pyspark.__version__"],"metadata":{"id":"kODasV-vZtQV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load the data"],"metadata":{"id":"CRtp6toeXmyy"}},{"cell_type":"code","source":["import urllib\n","import zipfile\n","\n","url = 'http://files.grouplens.org/datasets/movielens/ml-20m.zip'\n","filehandle, _ = urllib.request.urlretrieve(url)\n","zip_file_object = zipfile.ZipFile(filehandle, 'r')\n","zip_file_object.namelist()\n","zip_file_object.extractall()"],"metadata":{"id":"oR6A4_JhV1Fb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["movies_path = \"ml-20m/movies.csv\"\n","ratings_path = \"ml-20m/ratings.csv\"\n"],"metadata":{"id":"U6PXb1wjVqxd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["movies_df = spark.read.options(header=True).csv(movies_path)\n","ratings_df = spark.read.options(header=True).csv(ratings_path).sample(0.01)"],"metadata":{"id":"qV7r85g0V9VB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["movies_rdd = movies_df.rdd\n","ratings_rdd = ratings_df.rdd"],"metadata":{"id":"PB1wLA-bWfl9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Reminders\n","\n","**A RDD can be transformed into a other Python object** when an Spark action is called like a list (with `take(n)` for example):"],"metadata":{"id":"FBZnHuBeZ_5h"}},{"cell_type":"code","source":["type(movies_rdd)"],"metadata":{"id":"D8RX_BA2Wq2E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = movies_df.rdd.take(2)"],"metadata":{"id":"3RdwAZLpWvZ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result"],"metadata":{"id":"pYZFe_UxW8Ws"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(result)"],"metadata":{"id":"fjtUiNLrXGIB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Spark function** can be a **Spark action** that triggers the computation or a **Spark transformation** that is evalued lazily."],"metadata":{"id":"DeCDXt5Zao_m"}},{"cell_type":"markdown","source":["# Errors\n"],"metadata":{"id":"qwf4-h9BXQP1"}},{"cell_type":"markdown","source":["## Case sensitive"],"metadata":{"id":"Po5gh_ohb0kW"}},{"cell_type":"markdown","source":["Spark does not ignore the case, it is **case sensitive** (not like SQL).\n","`userId` is different than `userID`:"],"metadata":{"id":"VACTLnJObWg7"}},{"cell_type":"code","source":["ratings_rdd.map(lambda x: {'userId': x['userId']}).take(2)"],"metadata":{"id":"SKTXwkWJb-3-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ratings_rdd.map(lambda x: {'userID': x['userID']}).take(2)"],"metadata":{"id":"S1XDWJLMcNLB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## The methods collect() or take(n) does not work"],"metadata":{"id":"pom0YKMcYHGy"}},{"cell_type":"markdown","source":["### Root cause 1: The object has not the method"],"metadata":{"id":"g7MfWmgOYU_E"}},{"cell_type":"code","source":["result.collect()"],"metadata":{"id":"buqTtRAwXIZT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["See the auto-completion on the methods on the object (`Ctrl + Space` keyboard shortcut) and the type of your object:"],"metadata":{"id":"t2Nl_CHTYiNk"}},{"cell_type":"code","source":["result."],"metadata":{"id":"YG5fk0t3XMq8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["See with with the `dir` directly:"],"metadata":{"id":"_Fo0hBXBYyo8"}},{"cell_type":"code","source":["dir(result)"],"metadata":{"id":"JBTw2bW8YuT3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["See official documentation of Python:\n","https://docs.python.org/fr/3.8/tutorial/datastructures.html"],"metadata":{"id":"Y79PAmJrcjoO"}},{"cell_type":"markdown","source":["### Root cause 2: The lazy evaluation"],"metadata":{"id":"WAoIop9tbNb4"}},{"cell_type":"code","source":["result = ratings_rdd.map(lambda x: {'userID': x['userID']})"],"metadata":{"id":"SPGvqqitcpgR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result.take(2)"],"metadata":{"id":"ZBHbg5OpcsrF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(result)"],"metadata":{"id":"vHEYZPCEdF42"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result."],"metadata":{"id":"EdYd0u_5dmFS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dir(result)"],"metadata":{"id":"6M4V9Chvdhfi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The problem is before in the chain of functions evaluated lazily, the object RDD has the collect or take method, it is a lzay evaluation."],"metadata":{"id":"m29ki1JzdNuU"}},{"cell_type":"markdown","source":["The difference between **take(n)** and **collect()**:"],"metadata":{"id":"Yamyo902dsgZ"}},{"cell_type":"code","source":["result.take"],"metadata":{"id":"wfYNo3djduPx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result.collect"],"metadata":{"id":"VB4h9aAld246"},"execution_count":null,"outputs":[]}]}